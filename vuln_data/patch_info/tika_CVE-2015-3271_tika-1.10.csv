Fix_Path,Fix_Src
"tika-server/src/main/java/org/apache/tika/server/resource/TikaResource.java:[81,430]:TikaResource","public class TikaResource {
    public static final String GREETING = ""This is Tika Server. Please PUT\n"";
    public static final String X_TIKA_OCR_HEADER_PREFIX = ""X-Tika-OCR"";
    public static final String X_TIKA_PDF_HEADER_PREFIX = ""X-Tika-PDF"";


    private static final Log logger = LogFactory.getLog(TikaResource.class);

    private static TikaConfig tikaConfig;
    private static DigestingParser.Digester digester = null;

    public static void init(TikaConfig config, DigestingParser.Digester digestr) {
        tikaConfig = config;
        digester = digestr;
    }

    static {
        ExtractorFactory.setAllThreadsPreferEventExtractors(true);
    }

    @SuppressWarnings(""serial"")
    public static Parser createParser() {
        final Parser parser = new AutoDetectParser(tikaConfig);

        Map<MediaType, Parser> parsers = ((AutoDetectParser)parser).getParsers();
        parsers.put(MediaType.APPLICATION_XML, new HtmlParser());
        ((AutoDetectParser)parser).setParsers(parsers);

        ((AutoDetectParser)parser).setFallback(new Parser() {
            public Set<MediaType> getSupportedTypes(ParseContext parseContext) {
                return parser.getSupportedTypes(parseContext);
            }

            public void parse(InputStream inputStream, ContentHandler contentHandler, Metadata metadata, ParseContext parseContext) {
                throw new WebApplicationException(Response.Status.UNSUPPORTED_MEDIA_TYPE);
            }
        });
        if (digester != null) {
            return new DigestingParser(parser, digester);
        }
        return parser;
    }

    public static TikaConfig getConfig() {
        return tikaConfig;
    }

    public static String detectFilename(MultivaluedMap<String, String> httpHeaders) {

        String disposition = httpHeaders.getFirst(""Content-Disposition"");
        if (disposition != null) {
            try {
                ContentDisposition c = new ContentDisposition(disposition);

                // only support ""attachment"" dispositions
                if (""attachment"".equals(c.getDisposition())) {
                    String fn = c.getParameter(""filename"");
                    if (fn != null) {
                        return fn;
                    }
                }
            } catch (ParseException e) {
                // not a valid content-disposition field
            	e.printStackTrace();
            	logger.warn(String.format(
                        Locale.ROOT,
                        ""Parse exception %s determining content disposition"",
                        e.getMessage()
                ), e);
            }
        }

        // this really should not be used, since it's not an official field
        return httpHeaders.getFirst(""File-Name"");
    }

    public static void fillParseContext(ParseContext parseContext, MultivaluedMap<String, String> httpHeaders,
                                        Parser embeddedParser) {
        TesseractOCRConfig ocrConfig = new TesseractOCRConfig();
        PDFParserConfig pdfParserConfig = new PDFParserConfig();
        for (String key : httpHeaders.keySet()) {
            if (StringUtils.startsWith(key, X_TIKA_OCR_HEADER_PREFIX)) {
                processHeaderConfig(httpHeaders, ocrConfig, key, X_TIKA_OCR_HEADER_PREFIX);
            } else if (StringUtils.startsWith(key, X_TIKA_PDF_HEADER_PREFIX)) {
                processHeaderConfig(httpHeaders, pdfParserConfig, key, X_TIKA_PDF_HEADER_PREFIX);
            }
        }
        parseContext.set(TesseractOCRConfig.class, ocrConfig);
        parseContext.set(PDFParserConfig.class, pdfParserConfig);
        if (embeddedParser != null) {
            parseContext.set(Parser.class, embeddedParser);
        }
    }

    /**
     * Utility method to set a property on a class via reflection.
     *
     * @param httpHeaders the HTTP headers set.
     * @param object      the <code>Object</code> to set the property on.
     * @param key         the key of the HTTP Header.
     * @param prefix      the name of the HTTP Header prefix used to find property.
     * @throws WebApplicationException thrown when field cannot be found.
     */
    private static void processHeaderConfig(MultivaluedMap<String, String> httpHeaders, Object object, String key, String prefix) {
        try {
            String property = StringUtils.removeStart(key, prefix);
            Field field = object.getClass().getDeclaredField(StringUtils.uncapitalize(property));
            field.setAccessible(true);
            if (field.getType() == String.class) {
                field.set(object, httpHeaders.getFirst(key));
            } else if (field.getType() == int.class) {
                field.setInt(object, Integer.parseInt(httpHeaders.getFirst(key)));
            } else if (field.getType() == double.class) {
                field.setDouble(object, Double.parseDouble(httpHeaders.getFirst(key)));
            } else if (field.getType() == boolean.class) {
                field.setBoolean(object, Boolean.parseBoolean(httpHeaders.getFirst(key)));
            }
        } catch (Throwable ex) {
            throw new WebApplicationException(String.format(Locale.ROOT,
                    ""%s is an invalid %s header"", key, X_TIKA_OCR_HEADER_PREFIX));
        }
    }

    @SuppressWarnings(""serial"")
    public static void fillMetadata(Parser parser, Metadata metadata, ParseContext context, MultivaluedMap<String, String> httpHeaders) {
        String fileName = detectFilename(httpHeaders);
        if (fileName != null) {
            metadata.set(TikaMetadataKeys.RESOURCE_NAME_KEY, fileName);
        }

        String contentTypeHeader = httpHeaders.getFirst(HttpHeaders.CONTENT_TYPE);
        javax.ws.rs.core.MediaType mediaType = contentTypeHeader == null ? null
                : javax.ws.rs.core.MediaType.valueOf(contentTypeHeader);
        if (mediaType != null && ""xml"".equals(mediaType.getSubtype())) {
            mediaType = null;
        }

        if (mediaType != null && mediaType.equals(javax.ws.rs.core.MediaType.APPLICATION_OCTET_STREAM_TYPE)) {
            mediaType = null;
        }

        if (mediaType != null) {
            metadata.add(org.apache.tika.metadata.HttpHeaders.CONTENT_TYPE, mediaType.toString());

            final Detector detector = getDetector(parser);

            setDetector(parser, new Detector() {
                public MediaType detect(InputStream inputStream, Metadata metadata) throws IOException {
                    String ct = metadata.get(org.apache.tika.metadata.HttpHeaders.CONTENT_TYPE);

                    if (ct != null) {
                        return MediaType.parse(ct);
                    } else {
                        return detector.detect(inputStream, metadata);
                    }
                }
            });
        }

        final String password = httpHeaders.getFirst(""Password"");
        if (password != null) {
            context.set(PasswordProvider.class, new PasswordProvider() {
                @Override
                public String getPassword(Metadata metadata) {
                    return password;
                }
            });
        }
    }

    public static void setDetector(Parser p, Detector detector) {
        AutoDetectParser adp = getAutoDetectParser(p);
        adp.setDetector(detector);
    }

    public static Detector getDetector(Parser p) {
        AutoDetectParser adp = getAutoDetectParser(p);
        return adp.getDetector();
    }

    private static AutoDetectParser getAutoDetectParser(Parser p) {
        //bit stinky
        if (p instanceof AutoDetectParser) {
            return (AutoDetectParser)p;
        } else if (p instanceof ParserDecorator) {
            Parser wrapped = ((ParserDecorator)p).getWrappedParser();
            if (wrapped instanceof AutoDetectParser) {
                return (AutoDetectParser)wrapped;
            }
            throw new RuntimeException(""Couldn't find AutoDetectParser within: ""+wrapped.getClass());

        }
        throw new RuntimeException(""Couldn't find AutoDetectParser within: ""+p.getClass());

    }

    public static void parse(Parser parser, Log logger, String path, InputStream inputStream,
                             ContentHandler handler, Metadata metadata, ParseContext parseContext) throws IOException {
        inputStream = TikaInputStream.get(inputStream);
        try {
            parser.parse(inputStream, handler, metadata, parseContext);
        } catch (SAXException e) {
            throw new TikaServerParseException(e);
        } catch (EncryptedDocumentException e) {
            logger.warn(String.format(
                    Locale.ROOT,
                    ""%s: Encrypted document"",
                    path
            ), e);
            throw new TikaServerParseException(e);
        } catch (Exception e) {
            logger.warn(String.format(
                    Locale.ROOT,
                    ""%s: Text extraction failed"",
                    path
            ), e);
            throw new TikaServerParseException(e);
        } finally {
            inputStream.close();
        }
    }

    public static void logRequest(Log logger, UriInfo info, Metadata metadata) {
        if (metadata.get(org.apache.tika.metadata.HttpHeaders.CONTENT_TYPE) == null) {
            logger.info(String.format(
                    Locale.ROOT,
                    ""%s (autodetecting type)"",
                    info.getPath()
            ));
        } else {
            logger.info(String.format(
                    Locale.ROOT,
                    ""%s (%s)"",
                    info.getPath(),
                    metadata.get(org.apache.tika.metadata.HttpHeaders.CONTENT_TYPE)
            ));
        }
    }

    @GET
    @Produces(""text/plain"")
    public String getMessage() {
        return GREETING;
    }

    @POST
    @Consumes(""multipart/form-data"")
    @Produces(""text/plain"")
    @Path(""form"")
    public StreamingOutput getTextFromMultipart(Attachment att, @Context final UriInfo info) {
        return produceText(att.getObject(InputStream.class), att.getHeaders(), info);
    }

    @PUT
    @Consumes(""*/*"")
    @Produces(""text/plain"")
    public StreamingOutput getText(final InputStream is, @Context HttpHeaders httpHeaders, @Context final UriInfo info) {
        return produceText(is, httpHeaders.getRequestHeaders(), info);
    }

    public StreamingOutput produceText(final InputStream is, MultivaluedMap<String, String> httpHeaders, final UriInfo info) {
        final Parser parser = createParser();
        final Metadata metadata = new Metadata();
        final ParseContext context = new ParseContext();

        fillMetadata(parser, metadata, context, httpHeaders);
        fillParseContext(context, httpHeaders, parser);

        logRequest(logger, info, metadata);

        return new StreamingOutput() {
            public void write(OutputStream outputStream) throws IOException, WebApplicationException {
                Writer writer = new OutputStreamWriter(outputStream, IOUtils.UTF_8);

                BodyContentHandler body = new BodyContentHandler(new RichTextContentHandler(writer));

                try {
                    parse(parser, logger, info.getPath(), is, body, metadata, context);
                } finally {
                    is.close();
                }
            }
        };
    }

    @POST
    @Consumes(""multipart/form-data"")
    @Produces(""text/html"")
    @Path(""form"")
    public StreamingOutput getHTMLFromMultipart(Attachment att, @Context final UriInfo info) {
        return produceOutput(att.getObject(InputStream.class), att.getHeaders(), info, ""html"");
    }

    @PUT
    @Consumes(""*/*"")
    @Produces(""text/html"")
    public StreamingOutput getHTML(final InputStream is, @Context HttpHeaders httpHeaders, @Context final UriInfo info) {
        return produceOutput(is, httpHeaders.getRequestHeaders(), info, ""html"");
    }

    @POST
    @Consumes(""multipart/form-data"")
    @Produces(""text/xml"")
    @Path(""form"")
    public StreamingOutput getXMLFromMultipart(Attachment att, @Context final UriInfo info) {
        return produceOutput(att.getObject(InputStream.class), att.getHeaders(), info, ""xml"");
    }

    @PUT
    @Consumes(""*/*"")
    @Produces(""text/xml"")
    public StreamingOutput getXML(final InputStream is, @Context HttpHeaders httpHeaders, @Context final UriInfo info) {
        return produceOutput(is, httpHeaders.getRequestHeaders(), info, ""xml"");
    }

    private StreamingOutput produceOutput(final InputStream is, final MultivaluedMap<String, String> httpHeaders,
                                          final UriInfo info, final String format) {
        final Parser parser = createParser();
        final Metadata metadata = new Metadata();
        final ParseContext context = new ParseContext();

        fillMetadata(parser, metadata, context, httpHeaders);
        fillParseContext(context, httpHeaders, parser);


        logRequest(logger, info, metadata);

        return new StreamingOutput() {
            public void write(OutputStream outputStream)
                    throws IOException, WebApplicationException {
                Writer writer = new OutputStreamWriter(outputStream, IOUtils.UTF_8);
                ContentHandler content;

                try {
                    SAXTransformerFactory factory = (SAXTransformerFactory) SAXTransformerFactory.newInstance();
                    TransformerHandler handler = factory.newTransformerHandler();
                    handler.getTransformer().setOutputProperty(OutputKeys.METHOD, format);
                    handler.getTransformer().setOutputProperty(OutputKeys.INDENT, ""yes"");
                    handler.getTransformer().setOutputProperty(OutputKeys.ENCODING, IOUtils.UTF_8.name());
                    handler.setResult(new StreamResult(writer));
                    content = new ExpandedTitleContentHandler(handler);
                } catch (TransformerConfigurationException e) {
                    throw new WebApplicationException(e);
                }

                parse(parser, logger, info.getPath(), is, content, metadata, context);
            }
        };
    }
}
"
"tika-server/src/main/java/org/apache/tika/server/resource/TikaResource.java:[337,339]:getText","    public StreamingOutput getText(final InputStream is, @Context HttpHeaders httpHeaders, @Context final UriInfo info) {
        return produceText(is, httpHeaders.getRequestHeaders(), info);
    }
"
"tika-server/src/main/java/org/apache/tika/server/resource/RecursiveMetadataResource.java:[44,85]:RecursiveMetadataResource","public class RecursiveMetadataResource {
    private static final Log logger = LogFactory.getLog(RecursiveMetadataResource.class);

    @POST
    @Consumes(""multipart/form-data"")
    @Produces({""text/csv"", ""application/json""})
    @Path(""form"")
    public Response getMetadataFromMultipart(Attachment att, @Context UriInfo info) throws Exception {
        return Response.ok(
                parseMetadata(att.getObject(InputStream.class), att.getHeaders(), info)).build();
    }

    @PUT
    @Produces(""application/json"")
    public Response getMetadata(InputStream is, @Context HttpHeaders httpHeaders, @Context UriInfo info) throws Exception {
        return Response.ok(
                parseMetadata(is, httpHeaders.getRequestHeaders(), info)).build();
    }

	private MetadataList parseMetadata(InputStream is,
			MultivaluedMap<String, String> httpHeaders, UriInfo info)
			throws Exception {
		final Metadata metadata = new Metadata();
		final ParseContext context = new ParseContext();
		Parser parser = TikaResource.createParser();
		// TODO: parameterize choice of handler and max chars?
		BasicContentHandlerFactory.HANDLER_TYPE type = BasicContentHandlerFactory.HANDLER_TYPE.TEXT;
		RecursiveParserWrapper wrapper = new RecursiveParserWrapper(parser,
				new BasicContentHandlerFactory(type, -1));
		TikaResource.fillMetadata(parser, metadata, context, httpHeaders);
		// no need to add parser to parse recursively
		TikaResource.fillParseContext(context, httpHeaders, null);
		TikaResource.logRequest(logger, info, metadata);
		TikaResource.parse(wrapper, logger, info.getPath(), is,
				new ProfilingHandler() {
					public void endDocument() {
						metadata.set(""language"", getLanguage().getLanguage());
					}
				}, metadata, context);
		return new MetadataList(wrapper.getMetadata());
	}
}
"
"tika-server/src/main/java/org/apache/tika/server/resource/RecursiveMetadataResource.java:[58,61]:getMetadata","    public Response getMetadata(InputStream is, @Context HttpHeaders httpHeaders, @Context UriInfo info) throws Exception {
        return Response.ok(
                parseMetadata(is, httpHeaders.getRequestHeaders(), info)).build();
    }
"
"tika-server/src/main/java/org/apache/tika/server/resource/MetadataResource.java:[44,134]:MetadataResource","public class MetadataResource {
    private static final Log logger = LogFactory.getLog(MetadataResource.class);

    @POST
    @Consumes(""multipart/form-data"")
    @Produces({""text/csv"", ""application/json"", ""application/rdf+xml""})
    @Path(""form"")
    public Response getMetadataFromMultipart(Attachment att, @Context UriInfo info) throws Exception {
        return Response.ok(
                parseMetadata(att.getObject(InputStream.class), att.getHeaders(), info)).build();
    }

    @PUT
    @Produces({""text/csv"", ""application/json"", ""application/rdf+xml""})
    public Response getMetadata(InputStream is, @Context HttpHeaders httpHeaders, @Context UriInfo info) throws Exception {
        return Response.ok(
                parseMetadata(is, httpHeaders.getRequestHeaders(), info)).build();
    }

    /**
     * Get a specific metadata field. If the input stream cannot be parsed, but a
     * value was found for the given metadata field, then the value of the field
     * is returned as part of a 200 OK response; otherwise a
     * {@link javax.ws.rs.core.Response.Status#BAD_REQUEST} is generated. If the stream was successfully
     * parsed but the specific metadata field was not found, then a
     * {@link javax.ws.rs.core.Response.Status#NOT_FOUND} is returned.
     * <p/>
     * Note that this method handles multivalue fields and returns possibly more
     * metadata value than requested.
     * <p/>
     * If you want XMP, you must be careful to specify the exact XMP key.
     * For example, ""Author"" will return nothing, but ""dc:creator"" will return the correct value.
     *
     * @param is          inputstream
     * @param httpHeaders httpheaders
     * @param info        info
     * @param field       the tika metadata field name
     * @return one of {@link javax.ws.rs.core.Response.Status#OK}, {@link javax.ws.rs.core.Response.Status#NOT_FOUND}, or
     * {@link javax.ws.rs.core.Response.Status#BAD_REQUEST}
     * @throws Exception
     */
    @PUT
    @Path(""{field}"")
    @Produces({""text/csv"", ""application/json"", ""application/rdf+xml"", ""text/plain""})
    public Response getMetadataField(InputStream is, @Context HttpHeaders httpHeaders,
                                     @Context UriInfo info, @PathParam(""field"") String field) throws Exception {

        // use BAD request to indicate that we may not have had enough data to
        // process the request
        Response.Status defaultErrorResponse = Response.Status.BAD_REQUEST;
        Metadata metadata = null;
        try {
            metadata = parseMetadata(is, httpHeaders.getRequestHeaders(), info);
            // once we've parsed the document successfully, we should use NOT_FOUND
            // if we did not see the field
            defaultErrorResponse = Response.Status.NOT_FOUND;
        } catch (Exception e) {
            logger.info(""Failed to process field "" + field, e);
        }

        if (metadata == null || metadata.get(field) == null) {
            return Response.status(defaultErrorResponse).entity(""Failed to get metadata field "" + field).build();
        }

        // remove fields we don't care about for the response
        for (String name : metadata.names()) {
            if (!field.equals(name)) {
                metadata.remove(name);
            }
        }
        return Response.ok(metadata).build();
    }

    private Metadata parseMetadata(InputStream is,
                                   MultivaluedMap<String, String> httpHeaders, UriInfo info) throws IOException {
        final Metadata metadata = new Metadata();
        final ParseContext context = new ParseContext();
        Parser parser = TikaResource.createParser();
        TikaResource.fillMetadata(parser, metadata, context, httpHeaders);
        //no need to pass parser for embedded document parsing
        TikaResource.fillParseContext(context, httpHeaders, null);
        TikaResource.logRequest(logger, info, metadata);
        TikaResource.parse(parser, logger, info.getPath(), is,
                new ProfilingHandler() {
                    public void endDocument() {
                        metadata.set(""language"", getLanguage().getLanguage());
                    }},
                metadata, context);
        return metadata;
    }
}
"
"tika-server/src/main/java/org/apache/tika/server/resource/MetadataResource.java:[58,61]:getMetadata","    public Response getMetadata(InputStream is, @Context HttpHeaders httpHeaders, @Context UriInfo info) throws Exception {
        return Response.ok(
                parseMetadata(is, httpHeaders.getRequestHeaders(), info)).build();
    }
"
"tika-server/src/main/java/org/apache/tika/server/resource/MetadataResource.java:[88,115]:getMetadataField","    public Response getMetadataField(InputStream is, @Context HttpHeaders httpHeaders,
                                     @Context UriInfo info, @PathParam(""field"") String field) throws Exception {

        // use BAD request to indicate that we may not have had enough data to
        // process the request
        Response.Status defaultErrorResponse = Response.Status.BAD_REQUEST;
        Metadata metadata = null;
        try {
            metadata = parseMetadata(is, httpHeaders.getRequestHeaders(), info);
            // once we've parsed the document successfully, we should use NOT_FOUND
            // if we did not see the field
            defaultErrorResponse = Response.Status.NOT_FOUND;
        } catch (Exception e) {
            logger.info(""Failed to process field "" + field, e);
        }

        if (metadata == null || metadata.get(field) == null) {
            return Response.status(defaultErrorResponse).entity(""Failed to get metadata field "" + field).build();
        }

        // remove fields we don't care about for the response
        for (String name : metadata.names()) {
            if (!field.equals(name)) {
                metadata.remove(name);
            }
        }
        return Response.ok(metadata).build();
    }
"
"tika-server/src/main/java/org/apache/tika/server/resource/UnpackerResource.java:[67,262]:UnpackerResource","public class UnpackerResource {
    public static final String TEXT_FILENAME = ""__TEXT__"";
    private static final Log logger = LogFactory.getLog(UnpackerResource.class);
    private static final String META_FILENAME = ""__METADATA__"";

    public static void metadataToCsv(Metadata metadata, OutputStream outputStream) throws IOException {
        CSVWriter writer = new CSVWriter(new OutputStreamWriter(outputStream, org.apache.tika.io.IOUtils.UTF_8));

        for (String name : metadata.names()) {
            String[] values = metadata.getValues(name);
            ArrayList<String> list = new ArrayList<String>(values.length + 1);
            list.add(name);
            list.addAll(Arrays.asList(values));
            writer.writeNext(list.toArray(values));
        }

        writer.close();
    }

    @Path(""/{id:(/.*)?}"")
    @PUT
    @Produces({""application/zip"", ""application/x-tar""})
    public Map<String, byte[]> unpack(
            InputStream is,
            @Context HttpHeaders httpHeaders,
            @Context UriInfo info
    ) throws Exception {
        return process(is, httpHeaders, info, false);
    }

    @Path(""/all{id:(/.*)?}"")
    @PUT
    @Produces({""application/zip"", ""application/x-tar""})
    public Map<String, byte[]> unpackAll(
            InputStream is,
            @Context HttpHeaders httpHeaders,
            @Context UriInfo info
    ) throws Exception {
        return process(is, httpHeaders, info, true);
    }

    private Map<String, byte[]> process(
            InputStream is,
            @Context HttpHeaders httpHeaders,
            @Context UriInfo info,
            boolean saveAll
    ) throws Exception {
        Metadata metadata = new Metadata();
        ParseContext pc = new ParseContext();

        Parser parser = TikaResource.createParser();
        if (parser instanceof DigestingParser) {
            //no need to digest for unwrapping
            parser = ((DigestingParser)parser).getWrappedParser();
        }

        TikaResource.fillMetadata(parser, metadata, pc, httpHeaders.getRequestHeaders());
        TikaResource.logRequest(logger, info, metadata);

        ContentHandler ch;
        ByteArrayOutputStream text = new ByteArrayOutputStream();

        if (saveAll) {
            ch = new BodyContentHandler(new RichTextContentHandler(new OutputStreamWriter(text, org.apache.tika.io.IOUtils.UTF_8)));
        } else {
            ch = new DefaultHandler();
        }

        Map<String, byte[]> files = new HashMap<String, byte[]>();
        MutableInt count = new MutableInt();

        pc.set(EmbeddedDocumentExtractor.class, new MyEmbeddedDocumentExtractor(count, files));
        TikaResource.parse(parser, logger, info.getPath(), is, ch, metadata, pc);

        if (count.intValue() == 0 && !saveAll) {
            throw new WebApplicationException(Response.Status.NO_CONTENT);
        }

        if (saveAll) {
            files.put(TEXT_FILENAME, text.toByteArray());

            ByteArrayOutputStream metaStream = new ByteArrayOutputStream();
            metadataToCsv(metadata, metaStream);

            files.put(META_FILENAME, metaStream.toByteArray());
        }

        return files;
    }

    private class MyEmbeddedDocumentExtractor implements EmbeddedDocumentExtractor {
        private final MutableInt count;
        private final Map<String, byte[]> zout;

        MyEmbeddedDocumentExtractor(MutableInt count, Map<String, byte[]> zout) {
            this.count = count;
            this.zout = zout;
        }

        public boolean shouldParseEmbedded(Metadata metadata) {
            return true;
        }

        public void parseEmbedded(InputStream inputStream, ContentHandler contentHandler, Metadata metadata, boolean b) throws SAXException, IOException {
            ByteArrayOutputStream bos = new ByteArrayOutputStream();
            IOUtils.copy(inputStream, bos);
            byte[] data = bos.toByteArray();

            String name = metadata.get(TikaMetadataKeys.RESOURCE_NAME_KEY);
            String contentType = metadata.get(org.apache.tika.metadata.HttpHeaders.CONTENT_TYPE);

            if (name == null) {
                name = Integer.toString(count.intValue());
            }

            if (!name.contains(""."") && contentType != null) {
                try {
                    String ext = TikaResource.getConfig().getMimeRepository().forName(contentType).getExtension();

                    if (ext != null) {
                        name += ext;
                    }
                } catch (MimeTypeException e) {
                    logger.warn(""Unexpected MimeTypeException"", e);
                }
            }

            if (""application/vnd.openxmlformats-officedocument.oleObject"".equals(contentType)) {
                POIFSFileSystem poifs = new POIFSFileSystem(new ByteArrayInputStream(data));
                OfficeParser.POIFSDocumentType type = OfficeParser.POIFSDocumentType.detectType(poifs);

                if (type == OfficeParser.POIFSDocumentType.OLE10_NATIVE) {
                    try {
                        Ole10Native ole = Ole10Native.createFromEmbeddedOleObject(poifs);
                        if (ole.getDataSize() > 0) {
                            String label = ole.getLabel();

                            if (label.startsWith(""ole-"")) {
                                label = Integer.toString(count.intValue()) + '-' + label;
                            }

                            name = label;

                            data = ole.getDataBuffer();
                        }
                    } catch (Ole10NativeException ex) {
                        logger.warn(""Skipping invalid part"", ex);
                    }
                } else {
                    name += '.' + type.getExtension();
                }
            }

            final String finalName = name;

            if (data.length > 0) {
                zout.put(finalName, data);

                count.increment();
            } else {
                if (inputStream instanceof TikaInputStream) {
                    TikaInputStream tin = (TikaInputStream) inputStream;

                    if (tin.getOpenContainer() != null && tin.getOpenContainer() instanceof DirectoryEntry) {
                        POIFSFileSystem fs = new POIFSFileSystem();
                        copy((DirectoryEntry) tin.getOpenContainer(), fs.getRoot());
                        ByteArrayOutputStream bos2 = new ByteArrayOutputStream();
                        fs.writeFilesystem(bos2);
                        bos2.close();

                        zout.put(finalName, bos2.toByteArray());
                    }
                }
            }
        }

        protected void copy(DirectoryEntry sourceDir, DirectoryEntry destDir)
                throws IOException {
            for (Entry entry : sourceDir) {
                if (entry instanceof DirectoryEntry) {
                    // Need to recurse
                    DirectoryEntry newDir = destDir.createDirectory(entry.getName());
                    copy((DirectoryEntry) entry, newDir);
                } else {
                    // Copy entry
                    InputStream contents = new DocumentInputStream((DocumentEntry) entry);
                    try {
                        destDir.createDocument(entry.getName(), contents);
                    } finally {
                        contents.close();
                    }
                }
            }
        }
    }
}
"
"tika-server/src/main/java/org/apache/tika/server/resource/UnpackerResource.java:[108,155]:process","    private Map<String, byte[]> process(
            InputStream is,
            @Context HttpHeaders httpHeaders,
            @Context UriInfo info,
            boolean saveAll
    ) throws Exception {
        Metadata metadata = new Metadata();
        ParseContext pc = new ParseContext();

        Parser parser = TikaResource.createParser();
        if (parser instanceof DigestingParser) {
            //no need to digest for unwrapping
            parser = ((DigestingParser)parser).getWrappedParser();
        }

        TikaResource.fillMetadata(parser, metadata, pc, httpHeaders.getRequestHeaders());
        TikaResource.logRequest(logger, info, metadata);

        ContentHandler ch;
        ByteArrayOutputStream text = new ByteArrayOutputStream();

        if (saveAll) {
            ch = new BodyContentHandler(new RichTextContentHandler(new OutputStreamWriter(text, org.apache.tika.io.IOUtils.UTF_8)));
        } else {
            ch = new DefaultHandler();
        }

        Map<String, byte[]> files = new HashMap<String, byte[]>();
        MutableInt count = new MutableInt();

        pc.set(EmbeddedDocumentExtractor.class, new MyEmbeddedDocumentExtractor(count, files));
        TikaResource.parse(parser, logger, info.getPath(), is, ch, metadata, pc);

        if (count.intValue() == 0 && !saveAll) {
            throw new WebApplicationException(Response.Status.NO_CONTENT);
        }

        if (saveAll) {
            files.put(TEXT_FILENAME, text.toByteArray());

            ByteArrayOutputStream metaStream = new ByteArrayOutputStream();
            metadataToCsv(metadata, metaStream);

            files.put(META_FILENAME, metaStream.toByteArray());
        }

        return files;
    }
"
